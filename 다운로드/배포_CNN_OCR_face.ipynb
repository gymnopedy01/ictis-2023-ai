{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9kzjDMKvrTBE",
        "outputId": "6b6cb096-26d3-4029-b33c-dbfee56eca04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본이미지 크기 m x n \n",
        " 필터(filter, kernel) 크기 n*n\n",
        "  필터가 \n",
        "5. 패딩 (Padding)\n",
        " - Feature map 의 크기가 줄어들지 않도록 입력 데이터의  외곽에 지정된 픽셀만큼 특정값으로 채워 넣는것\n",
        " - 보통은 0으로 채움\n",
        " - 다음의 크기 만큼 상하 좌우에 padding(K:필터 크기)\n",
        " 6. 채널(Channel)\n",
        " - 1 whdfbdml epdlxj\n",
        " - 컬러 사진은 RGB 3개 성분의 3종의 이미지 -> 3채널\n",
        "   - 높이 39픽셀, 폭 31픽셀인 컬러사진(39,31,3)\n",
        " - 흑밸 사진 -> 1채널\n",
        "   - 높이 39 픽셀, 폭 31 픽셀인 흑백 사진 -> (39, 31, 1)\n",
        " 7 활성화 및 활성화 맵 (Activation map)\n",
        "  - 활성화: \n",
        "   - feature map의 값에 환성화 함수를 적용하는 것\n",
        "  - 활성화 함수:\n",
        "   - reLU(rectified Linear Unit) 함수\n",
        "  - 활성화 맵\n",
        "   - Feature map을 활성화 한 결과인 2차원 맵 \n",
        "8 풀링(pooing)\n",
        "- 합성곱(convolution)의 결과의 크기를 줄이거나 특정 데이터를 강조하는 용도로 사용\n",
        "- 종류\n",
        "  - 최대 풀링\n",
        "  - 평균 풀링\n",
        "  - 확률적 풀링\n",
        "- Pooling size는 정사각형\n",
        "- 입력데이터의 크기는\n",
        "- \n",
        "\n",
        "9 Fully connected neural network\n",
        "= Flatten layer + Softmax layer\n",
        " - 마지막 풀링이 끝난 후 NxN 크기의 2D 결과를 1차원 벡터로 표현(flatten layer)후, 다층 신경망(softmax layer)을 구성\n",
        " - 다층 퍼셉트론: 오류역전파 학습(경사 하강법)\n",
        "\n",
        "\n",
        " Training Covolution Neural Networks\n",
        "  - Back propagation + stchastic gradient \n",
        "\n",
        "  CNN중 레쓰네 가 전이 학습"
      ],
      "metadata": {
        "id": "OF2o8XXX8raL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOuftFD2rTBF"
      },
      "source": [
        "# 1. CNN을 활용한 MNIST 손글씨 인식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFS68MJdrTBG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myn3NgsvrTBG"
      },
      "outputs": [],
      "source": [
        "# data 불러오기\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "print('학습셋 이미지: %d 개' % (X_train.shape[0]))\n",
        "print('테스트셋 이미지: %d 개' % (X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyYAJtpsrTBH"
      },
      "outputs": [],
      "source": [
        "# 숫자 출력\n",
        "import random\n",
        "n_samples=100\n",
        "indices = random.sample(range(X_train.shape[0]), n_samples)\n",
        "\n",
        "plt.figure(figsize=(15, 20))\n",
        "for i, idx in enumerate(indices):\n",
        "    plt.subplot(10,10, i+1)\n",
        "    plt.imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)\n",
        "    plt.title(Y_train[idx])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-4zhhIgrTBH"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaXqoidkrTBH"
      },
      "outputs": [],
      "source": [
        "# 2차원 영상, 1 channel\n",
        "X_train = X_train.reshape(X_train.shape[0],28,28,1)  # X_train.shape[0] : number of samples\n",
        "\n",
        "# 0~255 값을 0~1 사이 값으로 Min_Max 정규화\n",
        "X_train = X_train / 255.\n",
        "\n",
        "# 테스트셋 변환\n",
        "X_test = X_test.reshape(X_test.shape[0],  )/255.\n",
        "\n",
        "Y_train = Y_train.reshape(-1,1)\n",
        "Y_test = Y_test.reshape(-1,1)\n",
        "\n",
        "print(X_train[0].shape)\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(Y_train.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiYLrgjJrTBH"
      },
      "outputs": [],
      "source": [
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAED9nPFrTBH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "MODEL_DIR = '/content/drive/MyDrive/ICTIS_2023/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZuhkdbxrTBH"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "             metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAuUwQA0rTBI"
      },
      "outputs": [],
      "source": [
        "# 모델 저장 조건 설정\n",
        "modelfile = MODEL_DIR+ 'MnistCNN_best.h5'  \n",
        "checkpointer = ModelCheckpoint(filepath=modelfile, \n",
        "                               monitor='val_loss', verbose=1, \n",
        "                               save_best_only=True)\n",
        "\n",
        "# 학습의 자동 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss',\n",
        "                                        patience=10)\n",
        "\n",
        "fit_history = model.fit(X_train, Y_train, \n",
        "                          validation_data=(X_test, Y_test),\n",
        "                          epochs=50,\n",
        "                          batch_size=200,\n",
        "                          verbose=0,\n",
        "                          callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "print(\"Train Accuracy:\", model.evaluate(X_train, Y_train)[1])\n",
        "print(\"Test Accuracy:\",  model.evaluate(X_test, Y_test)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVJ1c4bLrTBI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#학습 이력 확인하기\n",
        "vloss = fit_history.history['val_loss'] # 테스트셋 loss\n",
        "loss = fit_history.history['loss'] # 학습셋  \n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "epoch = np.arange(len(loss))\n",
        "plt.plot(epoch, vloss, c='r', marker='.', label='validation_loss')\n",
        "plt.plot(epoch, loss, c='b',  marker='.',label='loss')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "vacc = fit_history.history['val_accuracy'] # 테스트셋 \n",
        "acc = fit_history.history['accuracy'] # 학습셋 정확도\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "epoch = np.arange(len(acc))\n",
        "plt.plot(epoch, vacc, 'r', marker='.', label='validation_acc')\n",
        "plt.plot(epoch, acc, 'b',  marker='.', label='accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWFwzEtZdJv7"
      },
      "source": [
        "## ◆ CNN 모델 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sk1XwAgdJv7"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x = x_test.reshape(-1,  )/255.\n",
        "print(x.shape, x.min(), x.max())\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "modelfile = MODEL_DIR + 'MnistCNN_best.h5'\n",
        "model = load_model(modelfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd-HUmttdJv7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo0mNc4VdJv7"
      },
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QD0c5oxdJv7"
      },
      "outputs": [],
      "source": [
        "conv1 = keras.Model(inputs= model.input, outputs= model.layers[0].output)\n",
        "conv2 = keras.Model(inputs= model.input, outputs= model.layers[2].output)\n",
        "pool1 = keras.Model(inputs= model.input, outputs= model.layers[1].output)\n",
        "pool2 = keras.Model(inputs= model.input, outputs= model.layers[3].output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq8LXWpBdJv7"
      },
      "source": [
        "## - Kernel 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "458kAgphdJv7"
      },
      "outputs": [],
      "source": [
        "conv = model.layers\n",
        "\n",
        "print(conv.weights[0].shape, conv.weights[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC8gxHvodJv7"
      },
      "outputs": [],
      "source": [
        "conv.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1WNgkoEdJv7"
      },
      "outputs": [],
      "source": [
        "conv_weights = conv.weights[0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apOXkfafdJv8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(4, 8, figsize=(10,6))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(conv_weights[:,:,  , i*8 + j], \n",
        "                          cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brdR-9wMdJv8"
      },
      "source": [
        "## - Feature map 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6kKh0KQdJv8"
      },
      "outputs": [],
      "source": [
        "samples = [3, 2, 1, 18, 4, 8, 11, 0, 61, 7]\n",
        "inputs = x[samples]\n",
        "print(inputs.shape)\n",
        "y_true = y_test[samples]\n",
        "print(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lIIaC_HdJv8"
      },
      "outputs": [],
      "source": [
        "feature_maps_1 = conv1.predict(inputs)\n",
        "type(feature_maps_1), feature_maps_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMHqhAkPdJv8"
      },
      "outputs": [],
      "source": [
        "pool_maps_1 = pool1.predict(inputs)\n",
        "type(pool_maps_1), pool_maps_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTMN24SzdJv8"
      },
      "outputs": [],
      "source": [
        "feature_maps_2 = conv2.predict(inputs)\n",
        "type(feature_maps_2), feature_maps_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZGGcCFmdJv8"
      },
      "outputs": [],
      "source": [
        "pool_maps_2 = pool2.predict(inputs)\n",
        "type(pool_maps_2), pool_maps_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvua0YIQdJv8"
      },
      "outputs": [],
      "source": [
        "def feature_map_1(k):\n",
        "    fig, axs = plt.subplots(4, 8, figsize=(10,5))\n",
        "    for j  in range(4):\n",
        "        for i in range(8):\n",
        "            axs[j, i].imshow(feature_maps_1[k,:,:,i+j*8], cmap='gray')\n",
        "            axs[j, i].axis('off')\n",
        "            axs[j, i].grid(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0sN8JlEdJv8"
      },
      "outputs": [],
      "source": [
        "def pooling_layer_1(k):\n",
        "    fig, axs = plt.subplots(4, 8, figsize=(5,3))\n",
        "    for j  in range(4):\n",
        "        for i in range(8):\n",
        "            axs[j, i].imshow(pool_maps_1[k,:,:,i+j*8], cmap='gray')\n",
        "            axs[j, i].axis('off')\n",
        "            axs[j, i].grid(False)\n",
        "\n",
        "    plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGLsSUtFdJv8"
      },
      "outputs": [],
      "source": [
        "def feature_map_2(k):\n",
        "    fig, axs = plt.subplots(8, 8, figsize=(5,5))\n",
        "    for j  in range(8):\n",
        "        for i in range(8):\n",
        "            axs[j, i].imshow(feature_maps_2[k,:,:,i+j*8], cmap='gray')\n",
        "            axs[j, i].axis('off')\n",
        "            axs[j, i].grid(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY6IisEpdJv8"
      },
      "outputs": [],
      "source": [
        "def pooling_layer_2(k):\n",
        "    fig, axs = plt.subplots(8, 8, figsize=(3,3))\n",
        "    for j  in range(8):\n",
        "        for i in range(8):\n",
        "            axs[j, i].imshow(pool_maps_2[k,:,:,i+j*8], cmap='gray')\n",
        "            axs[j, i].axis('off')\n",
        "            axs[j, i].grid(False)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns5cD46idJv9"
      },
      "outputs": [],
      "source": [
        "def disp_featuremaps(k):  # 0 ~ 9\n",
        "    feature_map_1(k)\n",
        "    pooling_layer_1(k)\n",
        "    feature_map_2(k)\n",
        "    pooling_layer_2(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOrSdgtDdJv9"
      },
      "outputs": [],
      "source": [
        "disp_featuremaps(k=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ_tssNHdJv9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko6CgeR0rTBI"
      },
      "source": [
        "# 2. 이미지 OCR- 연속 문자 인식 프로젝트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogtX3VsrTBI"
      },
      "source": [
        "- imutils 설치 후 kernel 재부팅하지 않고 아래 코드 바로실행 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JyzsCM5rTBI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "IMG_DIR=\"/content/drive/MyDrive/ICTIS_2023/img/ocr/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMze86OurTBJ"
      },
      "source": [
        "## (1) 이미지에서 글자가 있는 영역 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7Ua2KVIrTBJ"
      },
      "outputs": [],
      "source": [
        "# 이미지 읽어 들이기 \n",
        "im = cv2.imread(IMG_DIR+'numbers.png')\n",
        "\n",
        "# 그레이스케일로 변환하고 블러링 후 이진화\n",
        "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "thresh = cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)\n",
        "\n",
        "# 윤곽 추출 \n",
        "contours, _ = cv2.findContours(thresh, \n",
        "                            cv2.RETR_ , \n",
        "                            cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# 추출한 윤곽을 bounding box 처리\n",
        "for cnt in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt) \n",
        "    if h < 20: continue # 너무 작으면 건너뛰기\n",
        "    red = (0, 0, 255)\n",
        "    cv2.rectangle(im, (x, y), (x+w, y+h), red, 2)\n",
        "    \n",
        "cv2.imwrite(IMG_DIR+'numbers-cnt.png', im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E19S9WJyrTBJ"
      },
      "source": [
        "- https://docs.opencv.org/3.0-beta/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=find%20contours#cv2.findContours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uColhF7rTBJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(im)\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP13GPTWrTBK"
      },
      "source": [
        "## (2) 개별 숫자 영역 추출하여 영상 리스트 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3qK-bkRrTBK"
      },
      "outputs": [],
      "source": [
        "# 추출한 좌표 정렬하기 \n",
        "rects = []\n",
        "im_w = im.shape[1]\n",
        "for i, cnt in enumerate(contours):\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    if w < 10 or h < 10: continue # 너무 작으면 생략하기\n",
        "    if w > im_w / 5: continue # 너무 크면 생략하기\n",
        "    y2 = round(y / 10) * 10 # Y좌표 맞추기\n",
        "    index = y2 * im_w  + x\n",
        "    rects.append((index, x, y, w, h))\n",
        "rects = sorted(rects, key=lambda x: ) # 정렬하기\n",
        "print(rects[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH2CRo_ErTBK"
      },
      "outputs": [],
      "source": [
        "# 해당 영역의 이미지 데이터 추출하기 \n",
        "X = []\n",
        "for i, r in enumerate(rects):\n",
        "    index, x, y, w, h = r\n",
        "    num = gray[y:y+h, x:x+w] # 부분 이미지 추출하기\n",
        "    # 반전하기\n",
        "    # 정사각형 내부에 그림 옮기기\n",
        "    ww = round((w if w > h else h) * 1.85) \n",
        "    spc = np.zeros((ww, ww))\n",
        "    wy = (ww-h)//2\n",
        "    wx = (ww-w)//2\n",
        "    spc[wy:wy+h, wx:wx+w] = num\n",
        "    num = cv2.resize(spc, (28, 28)) # MNIST 크기 맞추기\n",
        "    X.append(num)\n",
        "print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAZam-UurTBL"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuK9pPWgrTBL"
      },
      "source": [
        "##  (3) MLP 모델로 인식하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PCk6S0TrTBL"
      },
      "outputs": [],
      "source": [
        "X_test = X.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvzPZqbqrTBL"
      },
      "outputs": [],
      "source": [
        "X_test = X_test \n",
        "X_test.min(), X_test.max(), X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVleO71WrTBL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "modelfile = MODEL_DIR+\"MnistMLP_best.h5\"\n",
        "model = load_model(modelfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz3v0xMCrTBM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model,  show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb-Yj6YOrTBM"
      },
      "outputs": [],
      "source": [
        "# 예측하기 \n",
        "s = \"31415926535897932384\" + \\\n",
        "    \"62643383279502884197\" + \\\n",
        "    \"16939937510582097494\" + \\\n",
        "    \"45923078164062862089\" + \\\n",
        "    \"98628034825342117067\"\n",
        "answer = list(s)\n",
        "\n",
        "ng_list=[]\n",
        "ok = 0\n",
        "nlist = model.predict(X_test)\n",
        "for i, n in enumerate(nlist):\n",
        "    ans = n\n",
        "    if ans == int(answer[i]):\n",
        "        ok += 1\n",
        "    else:\n",
        "        print(\"[ng]\", i, \"번째\", ans, \"!=\", answer[i], np.int32(n*100))\n",
        "        ng_list.append(i)\n",
        "print('오답 수:', len(ng_list),'\\n 정답률:', ok / len(nlist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTBVXrT2rTBM"
      },
      "outputs": [],
      "source": [
        "# 오답 출력\n",
        "plt.figure(figsize=(8, 2))\n",
        "for i, idx in enumerate(ng_list):\n",
        "    plt.subplot(2,8, i+1)\n",
        "    plt.imshow( , cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PACiJ6N5rTBM"
      },
      "source": [
        "## (4) CNN 모델로 인식하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE02mFKarTBM"
      },
      "outputs": [],
      "source": [
        "X_test = X\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hWIoY_6rTBM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "modelfile =MODEL_DIR+'MnistCNN_best.h5'\n",
        "model = load_model(modelfile)\n",
        "\n",
        "plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4RjopZyrTBM"
      },
      "outputs": [],
      "source": [
        "# 예측하기 \n",
        "s = \"31415926535897932384\" + \\\n",
        "    \"62643383279502884197\" + \\\n",
        "    \"16939937510582097494\" + \\\n",
        "    \"45923078164062862089\" + \\\n",
        "    \"98628034825342117067\"\n",
        "answer = list(s)\n",
        "\n",
        "type\n",
        "ng_list=[]\n",
        "ok = 0\n",
        "nlist = model.predict(X_test)\n",
        "for i, n in enumerate(nlist):\n",
        "    ans = n\n",
        "    if ans == int(answer[i]):\n",
        "        ok += 1\n",
        "    else:\n",
        "        print(\"[ng]\", i, \"번째\", ans, \"!=\", answer[i], np.int32(n*100))\n",
        "        ng_list.append(i)\n",
        "print(\"정답률:\", ok / len(nlist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6ssBIbPrTBN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWKNTW5SrTBN"
      },
      "source": [
        "#  3. OpenCV로 얼굴 인식하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d26ZdRCurTBN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/ICTIS_2023/img/face/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqIEUhVCrTBN"
      },
      "source": [
        "## (1) 사진에서 얼굴부분 찾기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRP4jX_gNgxL"
      },
      "source": [
        "- https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPYoFJXYrTBN"
      },
      "outputs": [],
      "source": [
        "def face_detection(IMG_DIR, image_file, rst_file, min_size=(150,150)):\n",
        "    # 이미지 읽어 들이기 \n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    # 그레이스케일로 변환하기\n",
        "    image_gs = cv2.cvtColor(image, cv2.COLOR_ )\n",
        "\n",
        "    # 캐스케이드 파일의 경로 지정하기 \n",
        "    cascade_file = IMG_DIR+\"haarcascade_frontalface_alt.xml\"\n",
        "\n",
        "    # 얼굴 인식 특징 파일 읽어 들이기 \n",
        "    cascade = cv2.CascadeClassifier(cascade_file)\n",
        "\n",
        "    # 얼굴 인식 실행하기\n",
        "    face_list = cascade.detectMultiScale(image_gs,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=1,\n",
        "        minSize=min_size)\n",
        "    \n",
        "    if len(face_list) > 0:\n",
        "        # 인식한 부분 표시하기 \n",
        "        color = (0, 0, 255)  # Red\n",
        "        for face in face_list:\n",
        "            x,y,w,h = face\n",
        "            cv2.rectangle(image, (x,y), (x+w, y+h), color, thickness=8)\n",
        "        # 파일로 출력하기 \n",
        "        cv2.imwrite(rst_file, image)\n",
        "        return face_list\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEbbl_T7rTBN"
      },
      "outputs": [],
      "source": [
        "def displayResult(image_file, rst_file):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,2,1)\n",
        "    im = plt.imread(image_file)\n",
        "    plt.xlabel('Original')\n",
        "    plt.imshow(im)\n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    im = plt.imread(rst_file)\n",
        "    plt.xlabel('Result')\n",
        "    plt.imshow(im)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9HTp20orTBN"
      },
      "outputs": [],
      "source": [
        "image_file =IMG_DIR+ \"Lena.jpg\"\n",
        "rst_file= IMG_DIR+\"Lena_facedetect-output.png\"\n",
        "\n",
        "face_list = face_detection(IMG_DIR, image_file, rst_file)\n",
        "print(face_list)\n",
        "displayResult(image_file, rst_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEZkF1ANrTBO"
      },
      "outputs": [],
      "source": [
        "image_file =IMG_DIR+ \"people.png\"\n",
        "rst_file= IMG_DIR+\"people_facedetect-output.png\"\n",
        "\n",
        "face_list = face_detection(IMG_DIR, image_file, rst_file, (100,100))\n",
        "print(face_list)\n",
        "displayResult(image_file, rst_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWa9hBGmrTBO"
      },
      "source": [
        "##  (2) 얼굴 비식별화: 모자이크 방식 & Blurring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvgodffwrTBO"
      },
      "source": [
        "###  ㉠ 모자이크 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPYoNtZ0Yey9"
      },
      "outputs": [],
      "source": [
        "def make_mosaic(image_file, rst_file, face_list, mosaic_rate=10 ):\n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    color = (0, 0, 255)\n",
        "    for (x,y,w,h) in face_list:\n",
        "        # 얼굴 부분 자르기 \n",
        "        face_img = image[y:y+h, x:x+w]\n",
        "        # 자른 이미지를 지정한 배율로 확대/축소\n",
        "        face_img = cv2. (face_img, (w//mosaic_rate, h//mosaic_rate))\n",
        "        # 확대/축소한 그림을 원래 크기로\n",
        "        face_img = cv2. (face_img, (w, h), \n",
        "            interpolation=cv2.INTER_AREA)\n",
        "        # 원래 이미지에 붙이기 \n",
        "        image[y:y+h, x:x+w] = face_img\n",
        "    # 렌더링 결과를 파일에 출력\n",
        "    cv2.imwrite(rst_file, image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGq9-EOFYPl2"
      },
      "outputs": [],
      "source": [
        "image_file =IMG_DIR+ \"Lena.jpg\"\n",
        "rst_file= IMG_DIR+\"Lena-mosaic.jpg\"\n",
        "\n",
        "face_list= face_detection(IMG_DIR, image_file, rst_file, (70,70))\n",
        "print(face_list)\n",
        "make_mosaic(image_file, rst_file, face_list, mosaic_rate=10 )\n",
        "displayResult(image_file, rst_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081mdN_ArTBO"
      },
      "source": [
        "###  ㉡ Blurring 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTAqWK-GZgEy"
      },
      "outputs": [],
      "source": [
        "def make_blur(image_file, rst_file, face_list, ksize=23, sigma_X=30):\n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    color = (0, 0, 255)\n",
        "    for (x,y,w,h) in face_list:\n",
        "        # 얼굴 부분 자르기 \n",
        "        face_img = image[y:y+h, x:x+w]\n",
        "        # 블러링\n",
        "        face_img = cv2.GaussianBlur(face_img, (ksize, ksize), sigma_X)\n",
        "        # 원래 이미지에 붙이기 \n",
        "        image[y:y+h, x:x+w] = face_img\n",
        "    # 렌더링 결과를 파일에 출력\n",
        "    cv2.imwrite(rst_file, image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK5ij9maaVXs"
      },
      "outputs": [],
      "source": [
        "image_file =IMG_DIR+ \"Lena.jpg\"\n",
        "rst_file= IMG_DIR+\"Lena-mosaic.jpg\"\n",
        "face_list= face_detection(IMG_DIR, image_file, rst_file, (70,70))\n",
        "print(face_list)\n",
        "make_blur(image_file, rst_file, face_list, sigma_X=30 )\n",
        "displayResult(image_file, rst_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95UyO_AFrTBP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}